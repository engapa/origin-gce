# These are the default variables across all playbooks. This directory should contain
# all files referenced by the playbook when running in a docker container. To reference
# a file, assume the path is the same as playbooks/files or use a relative path to the
# playbook for lookup(...).
#
# This ensures that a relatively standard layout is used both inside and outside
# of a containerized image.

# Package and target versions

deployment_type: origin
ansible_pkg_mgr: yum
openshift_version: 1.5.0

# URLs and certs

openshift_master_cluster_public_hostname: gcp.mloso.com
openshift_master_cluster_hostname: internal-master.mloso.com
public_hosted_zone: mloso.com
dns_managed_zone: oso-gce-public-dns
wildcard_zone: svc.mloso.com
console_port: 443
internal_console_port: 8443
openshift_master_api_port: "8443"
openshift_master_console_port: "8443"
openshift_master_public_api_url: "https://gcp.mloso.com"
openshift_master_public_console_url: "https://gcp.mloso.com/console"
openshift_node_port_range: 30000-32000

# Authentication and authorization

# A set of initial roles to bootstrap the cluster with to bypass the need to copy the cluster-admin configuration file.
# Set to empty array for no defaults.
provision_role_mappings: [{'user': 'admin', 'role': 'cluster-admin'}]
provision_htpasswd_user_mappings: [{'user': 'admin', 'passwd': 'admin'}]

openshift_master_identity_providers:
- name: Google
  kind: GoogleIdentityProvider
  login: true
  challenge: false
  mapping_method: claim
  clientID: xxx-yyy.apps.googleusercontent.com
  clientSecret: zzz
  hostedDomain: example.comn
- name: Local Auth
  login: true
  challenge: true
  kind: HTPasswdPasswordIdentityProvider
  filename: /etc/openshift/openshift-passwd

# Cluster role binding
provision_cluster_role_binding_mappings:
- group: 'system:authenticated:oauth'
  #add-role: ['cluster-admin']
  remove-role: ['self-provisioner']

provision_scc_mapping:
  privileged:
  - 'enrique.garcia.pablos@bbva.com'
  - 'l.garcia.martin.contractor@bbva.com'

# Create new projects
provision_project_mappings:
- name: gpu
  # admin: admin
  # admin_role: admin
  # description: A new project
  # display_name: myproject
  node_selector: 'role=app-gpu'
  users:
  - {'name': 'enrique.garcia.pablos@bbva.com', 'role': 'admin' }
  - {'name': 'l.garcia.martin.contractor@bbva.com', 'role': 'admin' }
- name: app
  # admin: admin
  # admin_role: admin
  # description: A new project
  # display_name: myproject
  # node_selector: 'role=app'
  users:
  - {'name': 'enrique.garcia.pablos@bbva.com', 'role': 'admin' }
  - {'name': 'l.garcia.martin.contractor@bbva.com', 'role': 'admin' }

openshift_default_projects:
  logging:
    default_node_selector: 'role=infra'
  openshift-infra:
    default_node_selector: 'role=infra'

# Paths on the local system for the certificate files. If empty, self-signed
# certificate will be generated.
#provision_master_https_cert_file: "ssl.crt"
#provision_master_https_key_file: "ssl.key"
provision_master_https_cert_file: ""
provision_master_https_key_file: ""

# Post config setting sizes

# Configuration for cluster sizes
openshift_hosted_router_replicas: 1
openshift_hosted_registry_replicas: 1
# Must be true if provision_gce_instance_group_size_node_infra is zero.
openshift_schedulable: False

# GCE provisioning info

# Project ID and zone settings for Google Cloud
gce_project_id: "{{ (lookup('file', 'files/gce.json' ) | default('openshift-gce-devel') | from_json).get('project_id') }}"
gce_region_name: europe-west1
gce_zone_name: europe-west1-b
# A GCE service account JSON file that has sufficient permission to provision all instances
# on the cluster and to also act as the cloud provider (create service load balancers, set
# routes, provision PVs). You may restrict the permission of the account after creation.
gce_service_account_keyfile: "gce.json"
# The path to the private key on the host. If using the Docker image, this is set up by
# default to match "ssh-privatekey" and "ssh-publickey" from the data directory. If those
# files are not present, a unique key pair is generated and added to the project.
gce_ssh_private_key: /home/cloud-user/.ssh/google_compute_engine
# GCE service account JSON file that must have permission to read and write from the bucket
# named by provision_gce_registry_gcs_bucket. May be the same as gce_service_account_keyfile, but
# not recommended.
gcs_registry_keyfile: "gce.json"
# Required to be external unless a custom inventory is used
inventory_ip_type: external

# Extra tags to add to each instance template, must start with a comma
gce_extra_tags_master: ",preserve"
gce_extra_tags_node: ",preserve"
gce_extra_tags_node_infra: ",preserve"

# The sizes of instances to create
provision_gce_machine_type_master: n1-standard-4
provision_gce_machine_type_node: n1-standard-4
provision_gce_machine_type_node_infra: n1-standard-4

# Number of GPU for each node. Default value is 1
provision_gce_node_gpu_size: 1


# The instance sizes of each group. If node-infra is 0, you must set
# provision_gce_router_network_instance_group to ig-m
provision_gce_ig_type: unmanaged
provision_gce_instance_group_size_master: 1
provision_gce_instance_group_size_node_infra: 1
provision_gce_instance_group_size_node: 2
provision_gce_instance_group_size_node_gpu: 1

# Boot disks
provision_gce_instance_group_size_master_boot_disk: 40
provision_gce_instance_group_size_node_infra_boot_disk: 40
provision_gce_instance_group_size_node_boot_disk: 40
provision_gce_instance_group_size_node_gpu_boot_disk: 40

# The size of disks attached to each node. The Docker disk is for images and containers, the OpenShift
# disk is for empty dir volumes and local storage.
provision_gce_disk_size_node_docker: 50
provision_gce_disk_size_node_openshift: 50

# Provision prefix is a common identifier placed at the beginning of ALL GCE resource names
# to allow multiple clusters to be deployed in one GCE project.
provision_prefix: oso-ml
# Network name is a configuration parameter that is used by the cloud provider to provision
# service load balancers.
gce_network_name: "{{ provision_prefix }}-network"

# An image that is registered with the appropriate subscriptions (for RHEL) or
# Red Hat.
provision_gce_registered_image: oso-instance

# The name of a GCS bucket to create for the registry in the current project
provision_gce_registry_gcs_bucket: "{{ provision_prefix }}-registry-storage"

# Control which node group router traffic is targeted at. You may set this to ig-m to point
# to the master.
provision_gce_router_network_instance_group: ig-i # or: ig-m

# Provide a startup script file to the GCE instances
provision_gce_startup_script_file:
# Provide userdata to the gce instances
provision_gce_user_data_file:

# Monitoring
openshift_hosted_metrics_deploy: true
openshift_hosted_metrics_storage_kind: dynamic
openshift_metrics_image_version: v1.5.1

# Logging
openshift_hosted_logging_deploy: true
openshift_hosted_logging_storage_kind: dynamic
logging_elasticsearch_pvc_size: 50Gi
#openshift_logging_use_ops: true
#openshift_hosted_loggingops_storage_kind: dynamic
#logging_elasticsearch_ops_pvc_size: 50Gi

# Extensions for web console
openshift_master_extensions: [{'name': 'images', 'sourceDirectory': '/usr/share/origin/images'}]
openshift_master_oauth_templates:
  login: '/usr/share/origin/login.html'
  providerSelection: '/usr/share/origin/providerSelection.html'
login_background_image: "../console/extensions/images/back_image.jpg"